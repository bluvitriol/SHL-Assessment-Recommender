{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb45eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function 1 to scrape the whole page for all the assessment links\n",
    "2 for scraping a single assessment and extracting its details like url\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0557aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import regex as re\n",
    "\n",
    "CHROMEDRIVER_PATH = r\"C:\\Users\\Lenovo\\Desktop\\My_Notebooks\\SHL AI Research Intern Assessment\\chromedriver-win64\\chromedriver.exe\"\n",
    "START_URL = \"https://www.shl.com/solutions/products/product-catalog/\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')     \n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "service = Service(CHROMEDRIVER_PATH)\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def scrape_assessment(url, adaptive_support):\n",
    "    print(\"Scraping a single assessment!\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    try:\n",
    "        # print(\"trying for desciption\")\n",
    "        description_heading = driver.find_element(By.XPATH, \"//h4[text()='Description']\")\n",
    "        description = description_heading.find_element(By.XPATH, \"following-sibling::p[1]\").text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        description = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        details_heading=driver.find_element(By.XPATH, \"//h4[contains(text(), 'Assessment length')]\")\n",
    "        details_text = details_heading.find_element(By.XPATH, \"following-sibling::p[1]\").text\n",
    "        match = re.search(r'\\d+', details_text)\n",
    "        duration = int(match.group()) if match else \"N/A\"\n",
    "        \n",
    "       \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        duration = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        container = driver.find_elements(By.CSS_SELECTOR, \"p.product-catalogue__small-text\")\n",
    "\n",
    "        remote_support = \"N/A\"\n",
    "        test_type = []\n",
    "        test_type_map = {\n",
    "            \"A\": \"Ability & Aptitude\",\n",
    "            \"B\": \"Biodata & Situational Judgement\",\n",
    "            \"C\": \"Competencies\",\n",
    "            \"D\": \"Development & 360\",\n",
    "            \"E\": \"Assessment Exercises\",\n",
    "            \"K\": \"Knowledge & Skills\",\n",
    "            \"P\": \"Personality & Behavior\",\n",
    "            \"S\": \"Simulations\"\n",
    "        }\n",
    "\n",
    "        for p in container:\n",
    "            p_text = p.text.strip()\n",
    "\n",
    "            # if p_text.startswith(\"Remote Testing:\"):\n",
    "            if \"Remote Testing:\" in p_text:\n",
    "                # print(\"remote tesing section found\")\n",
    "                try:\n",
    "                    span = p.find_element(By.TAG_NAME, \"span\")\n",
    "                    span_class = span.get_attribute(\"class\")\n",
    "                    remote_support = \"Yes\" if \"-yes\" in span_class else \"No\"\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    remote_support = \"N/A\"\n",
    "\n",
    "            # elif p_text.startswith(\"Test Type:\"):\n",
    "            elif \"Test Type:\" in p_text:\n",
    "                # print(\"test type section found\")\n",
    "                try:\n",
    "                    keys = p.find_elements(By.CLASS_NAME, \"product-catalogue__key\")\n",
    "                    test_type_letters = [key.text.strip() for key in keys if key.text.strip()]\n",
    "                    test_type = [test_type_map.get(letter, f\"Unknown ({letter})\") for letter in test_type_letters]\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred: {e}\")\n",
    "                    test_type = []\n",
    "            # else:\n",
    "            #     print(\"no remote or test type section found!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        remote_support = \"N/A\"\n",
    "        test_type = []\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"adaptive_support\": adaptive_support,\n",
    "        \"description\": description,\n",
    "        \"duration\": duration,\n",
    "        \"remote_support\": remote_support,\n",
    "        \"test_type\": test_type\n",
    "    }\n",
    "\n",
    "\n",
    "def scrape_catalog_page(url):\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \"table tbody tr\"))\n",
    "    )\n",
    "\n",
    "    assessments_data = []\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \"table tbody tr\")\n",
    "    current_section = None\n",
    "    links_to_scrape = []\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            header = row.find_element(By.CLASS_NAME, \"custom__table-heading__title\").text\n",
    "            if header in \"Individual Test Solutions\":\n",
    "                current_section = header\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            pass\n",
    "\n",
    "        if current_section and current_section.strip() == \"Individual Test Solutions\":\n",
    "            # print(\"Individual test solutions section found!\")\n",
    "            try:\n",
    "                link_element = row.find_element(By.CSS_SELECTOR, \"td.custom__table-heading__title > a\")\n",
    "                assessment_url = link_element.get_attribute(\"href\")\n",
    "\n",
    "                td_elements = row.find_elements(By.CLASS_NAME, \"custom__table-heading__general\")\n",
    "                # print(f\"first adaptive element: {td_elements}\")\n",
    "                adaptive_td = td_elements[1]\n",
    "\n",
    "                adaptive_support = \"No\"\n",
    "\n",
    "                try:\n",
    "                    span = adaptive_td.find_element(By.TAG_NAME, \"span\")\n",
    "                    adaptive_class = span.get_attribute(\"class\")\n",
    "                    if \"-yes\" in adaptive_class:\n",
    "                        adaptive_support = \"Yes\"\n",
    "                        # print(f\"adaptive support: {adaptive_support}\")\n",
    "                except NoSuchElementException:\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error while checking adaptive: {e}\")\n",
    "\n",
    "                links_to_scrape.append((assessment_url, adaptive_support))\n",
    "            except Exception as e:\n",
    "                print(\"Error parsing row:\", e)\n",
    "\n",
    "\n",
    "\n",
    "    for url, adaptive_support in links_to_scrape:\n",
    "        try:\n",
    "            data = scrape_assessment(url, adaptive_support)\n",
    "            assessments_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping assessment detail page: {url}\\n{e}\")\n",
    "\n",
    "    return assessments_data\n",
    "\n",
    "def get_next_page_url(url):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(\"Looking for next page link...\")\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.pagination\"))\n",
    "        )\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1.5)  # short sleep for UI updates\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"li.pagination__item.-arrow.-next a\"))\n",
    "        )\n",
    "\n",
    "        next_buttons = driver.find_elements(By.CSS_SELECTOR, \"li.pagination__item.-arrow.-next a\")\n",
    "\n",
    "        print(f\"Found {len(next_buttons)} next button(s)\")\n",
    "\n",
    "        if next_buttons:\n",
    "            next_href = next_buttons[-1].get_attribute(\"href\")\n",
    "\n",
    "            full_url = \"https://www.shl.com\" + next_href if next_href.startswith(\"/\") else next_href\n",
    "            print(f\"Full next page URL: {full_url}\")\n",
    "            return full_url\n",
    "        else:\n",
    "            print(\"No next buttons found.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error getting next page:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(url):\n",
    "    # driver.get(url)\n",
    "    all_data = []\n",
    "    page_count = 1\n",
    "    current_url=url\n",
    "\n",
    "    while True:\n",
    "        print(f\"Scraping Page {page_count}\")\n",
    "        page_data = scrape_catalog_page(current_url)\n",
    "        all_data.extend(page_data)\n",
    "       \n",
    "        # driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(0.5)\n",
    "        next_url = get_next_page_url(current_url)\n",
    "        if not next_url:\n",
    "            break\n",
    "\n",
    "        current_url = next_url\n",
    "    \n",
    "        page_count += 1\n",
    "\n",
    "    with open(\"4shl_individual_assessments.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Scraped {len(all_data)} individual assessments.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(START_URL)\n",
    "    driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shlRAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
